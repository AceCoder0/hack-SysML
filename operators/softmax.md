它可以将 tensor 内的元素归一(有点像 norm)化为一个概率分布向量，即值域为（0，1），各概率之和为1。通常用在最后一层，用于多分类问题的输出，通常和交叉熵损失函数一起使用

soft 指：不像 hard 那样只留一个最大值，而是把大家的值都算出来

max 指凸显最大值，抑制远低于最大值的其他量

公示如下：

![](imgs/softmax-formula.png)

也可以尝试不用指数函数，直接算，会发现用指数后能把差距大的数值距离拉大。

指数函数求导方便，就是它本身。而它的特点是 x 轴上的变化，能让 y 轴显著变化。它的缺点是容易溢出

所以它的输入纬度不变，输出纬度也不变，torch

```
只是里面数值的值域变了.nn.Softmax(dim=None)
```
