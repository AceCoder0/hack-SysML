数据并行：适合中间数据比较多，而参数相对较少的情况。感觉就是 CV 模型呀，因为图像 数据 很大，而参数量比较小，因为是卷积
流水并行：适合中间数据较少，而参数相对较多的情况。stage 之间通信相对 all reduce 是廉价的。

GShard 是定义了一组：Replicate, Split, Shard 语义的 api，作为注解
Flex-FLow 是一套 DSL，需要修改模型 

oneflow 里有静态子图的概念，实现 checkpoint 时可以分析子图，删掉没用的。

共享资源形成的依赖：比如两个算子在执行过程中，会分配内存。而现有的框架都是分析发现算子的输入都 OK 了，就开始执行。这样会有分配失败，一直循环重试。

Oneflow 解决的思路：编译器分析每个 op 的最优内存配额，在运行时每个 op 的内存配额都是固定的，调度器在检查一个 op 是否可以被发射时，不仅看输入数据是否就绪 。而且看它的内存配额是否满足。否则不发射，一旦发射，这个 op 就可以一路畅通无阻 ，确保不会被阻塞。

## [为何 GPT 难以复现？](https://zhuanlan.zhihu.com/p/371499074)
讨论训练框架，得分清两类用户：系统研究员和算法研究员。我作为前者，去看 NV 的 Megatron-LM 实现，还是挺简单的。
不过对后者而言，确实有难度，但照猫画虎还是可以跑起来的。
框架类产品如果解决了易用性，那就没系统研究员的事了，算法研究员自己搞就行

### 看这篇的疑问：

2. 当机器数量增大时，通信开销增大：但流水并行，其实对通信要求不是很高。而tensor 并行下，all-reduce 效率并不是d的线性比，而是 


为了搞清楚 1F1B，可能得看一下 PipeDeam 论文。

## TODO:
0. 结合此文再看看 Megatron LM 的实现
1. 看看 OneFlow 怎么解决的
