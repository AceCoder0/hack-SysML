modal-labs llama-finetuning: CodeLlama：看起来直接 pytorch 里的组件就能搞定 7B，一万的数据集，30分钟内训练完10个 epoch

使用 4-bit Transformer 的 QLoRA, [Paper](https://arxiv.org/abs/2305.14314)
使用 PEFT(Parameter Efficient Fine Tune): [官方文档](https://huggingface.co/docs/peft/conceptual_guides/lora)

Supervised fine-tuning(SFT):

