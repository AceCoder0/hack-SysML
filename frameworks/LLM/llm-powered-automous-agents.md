把 LLM 当做 agents 里的核心控制模块是个很酷的概念。很多 poc demo，比如 AutoGPT，GPT-Engineer 和 BabyAGI ，都是例子。而 LLM 扩展为超越生成拷贝，故事，短篇和程序；可以被当做一个强大的通用问题解决器。

## Agent 系统的概览
在一个 LLM 驱动的自主 agent 系统里，LLM 充当 agents 的大脑，辅以若干关键组件：

* 规划(Planning)：
  * 子问题和分解
  * 反思与完善：能对过去的行为进行自我批评和反思，从错误中汲取教训，在未来完善他们，改进最终的结果

* Memory
  * 短期记忆：可以都当做 in-context learning (见 Prompt Engineering），利用模型的短期记忆来学习
  * 长期记忆：让 agent 有能力在长时间内保留和召回（无限）的信息，通常利用外部的向量存储和快速检索来实现。
  
* Tool use
  * agent 学习调用外部 api 来得到模型权重里所无法提供的额外信息（通常在预训练之后无法修改的），包括当前的信息，code 执行能力，访问转有的信息源等
  
![](imgs/overview-of-llm-powered-agents.png)

### Function calling
在一个 API 调用里，你可以给 gpt-3.5-turbo-0613 和 gpt-4-0613 描述函数，然后让默写智能地选择输出一个 JSON 对象来包含调用这些函数的参数。 Chat 补全的 API 并不会调用函数；而是，模型会产生你可以使用代码调用这些函数的 json

## 挑战
* 有限的上下文长度: 自我反思等能力，会受益于更长的上下文。虽然向量数据库可以提供更大的知识池子，但是他们的表达能力不如模型里的 full attention
* long-term 规划和任务分解里的挑战：人类是在不断试错中变得鲁棒的，而 LLMs 在很长的历史，以及高效探索解决空间上依然很有挑战
* 自研语言作为接口的可靠性: 当前系统还是依赖自然语言作为 LLMs 和外部工具和记忆之间的接口。但是这个可靠性存疑，LLMs 会有格式错误，偶尔会展示出叛逆(rebellious)的行为（比如拒绝执行一个指令）
