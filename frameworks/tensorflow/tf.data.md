1. 在解决的是什么问题？模型训练时，如何实现一套好的数据(前)处理的框架
2. 为何成功，标志/准是什么？性能高，而且能自动调优：并行、caching、static optimization，optional non-deterministic execution
3. 在前人基础上的关键创新是什么？
4. 关键结果有哪些？
5. 有哪些局限性？如何优化？
6. 这个工作可能有什么深远的影响？

## 1 摘要
输入需要高效处理：读入大量数据，应用复杂变换，把数据搬运到GPU上，同时需要和计算与通信重叠来达到最优性能。提供了一套 tf.data 的 API，能够
高效运行，让用户只关心在数据处理的逻辑上，而且用户定义的算子，可以组合、重用。而且公司内统计以及有其他论文里的数据，说明处理数据的时间占比很大，大约有20%的job，花了1/3的计算时间在输入数据处理上

决定并行的最优粒度和prefetch的数量也是比较难的，因为取决于负载的特点和可用的硬件资源.

GPU  和 TPU，是针对 ML计算中常见的线性代数做了优化的，但是对常见的数据处理操作支持的比较少。因此输入数据通常在 CPU 上处理，然后通过高效的传输到加速器上，来填满加速器的计算能力。由于加速器相比 CPU 而言代价
更高，让加速器在高利用率运行就很重要。

我们设计了 tf.data，是一个给ML任务构建和执行高效输入数据处理的数据管线。它提供通用的OP来参数化用户定义的函数，可以跨 ML 不同领域组装、复用。受关系型数据库，声明式集合库和数据并行大数据系统的启发，tf.data APIs
由无状态数据集组成，它是给用户用来定义了输入管线、有状态的迭代器的抽象。能够产出一系列元素，维持数据集里的当前位置。这些抽象让用户可以聚焦在他们输入管线上的应用逻辑，让管线高效运行留给 tf.data 运行时。tf.data
内部把输入管线数据集当作图，使用图改写的方法来静态优化。而且它能自动调整例如并行度和数据预取buffer大小等参数，这对于大部分 ML 用户而言，手工调整是非常有挑战的。

我们的评估表明：

1. 输入管线的性能对端到端训练时间影响非常大
2. tf.data 能通过软件管线，并行，静态优化来达到提高效率的目的
3. tf.data 的动态优化，避免了手工调整性能相关参数

例如，发现引入管线、并行后，Res50 上训练时间减少了10.4倍。之后应用更多优化，比如缓存和静态优化，进一步加快了2倍。

我们进一步证明，tf.data 的 auto-tuning 和专家手工优化的性能相当。

tf.data API和运行时开源了。在Google内部，他们在2017年开始就用起来了。能处理不同的数据模态，包括文本，图片，视频。

我们分析了公司内部各种不同特点的任务，分析出了百万个真实 ML 任务的输入 pipeline 特点，识别出了数据处理这块未来的工作。发现输入管线上使用的处理集合在不同 job 之间差别很大。对于75%的任务，处理后的数据集
大小比从存储拿到的数据集大小要小。说明预处理通常会降低数据的大小。最重要的是，发现一摸一样的输入管线会在不同任务之间重新执行，说明缓存处理之后的数据集会是一个非常有用的方法来提高 ML 输入数据处理的性能和效率。
我们也发现其他未来研究方向，比如靠近存储处理数据，输入数据数据与模型训练分开来避免 host 资源成为瓶颈。

## 2 输入数据需求
原始输入数据，比如图片、视频和文本文件，都会经过离线和在线预处理，然后再给模型训练用。离线数据处理包含从原始数据提取特征，验证数据，转换为二进制格式，比如 Avro，Parquet，或者 TFRecord，来让数据输入的吞吐更高。
批计算框架例如 Spark、Beam、Flume 都是适合离线处理。而一些数据处理，比如norm，可以 离线做，但也需要在线做的转换。比如图片模型需要依赖数据增强(data augmentation)，例如随机扭曲图片，提高精度。数据增广成倍增加了原始数据集的大小，
让输出存储到中间文件代价较高(prohibitive)。我们的工作聚焦在线上数据预处理，是作为 ML 训练任务里输入管线的一部分

输入管线可以概括为三个阶段：
1. extract
2. transform
3. load(ETL) process

第一阶段从存储系统读取数据。机器学习任务通常在大数据集上训练。图2说明13%的任务，在我们分析的百万任务里，读取了至少1TB的输入数据。这意味着不少训练任务来说，输入数据
在内存里放不下(不能这么算吧，看着夸张，但实际上是个循环，是累加起来的，实际只考虑一次 batch 的情况即可)。而且，超过96%的计算资源，花在了读取超过1TB数据上。(好像跟我们的情况不一样)

第二阶段转换数据到一个可以给 ML 训练计算用的格式。这个转换是给输入数据做变换，比如采样、重新排列，过滤数据来获得最相关的feature子集。训练图片模型时，常用的时做裁剪，调整大小，镜像反转，模糊图片。对于文本的管线，
训练样本通常需要分组并基于序列长度做batch。

第三阶段会把数据加载到加速器设备里，执行训练计算。

ML 训练对输入数据管线有特殊要求，总结如下并介绍了为什么没有被其他系统解决好

### 数据有序

### 性能



## 问题
1. 数据增广，如何提现到 POD 里的？一个 batch，bs=2，那么增广后，会变成4比如？


## 启发
1. CDF 的图，能用在我们分析allreduce速度，swap速度这种上面嘛？
2. 还有哪些团队，对数据输入效率有需要？我们是否能修改 pytorch，然后收集这些数据上来？
3. 输入数据集中，有不少操作是相同的，那可以缓存处理好的数据，提高效率、性能
4. 大部分任务的执行时间都很短，会在1s内结束，所以优化异步传输，节省那100ms很有必要。
5. 知道 UP 上最近一周 Top3 的网络结构和各自的耗时情况
6. 我们还能告诉用户，你的训练，读取了多少数据（几T）,耗了多少W。可以只针对大型任务进行分析，对长尾可以做累加
