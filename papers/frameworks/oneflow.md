1. 在解决的是什么问题？现有 DL 框架在大模型上使用和实现复杂的问题
2. 为何成功，标志/准是什么？
3. 在前人基础上的关键创新是什么？ SBP 的分布式抽象和 actor 模型来简化依赖和执行的运行时关系: 能管理资源限制、数据移动和计算三种依赖
4. 关键结果有哪些？简单、整洁，效率比其他要高
5. 有哪些局限性？如何优化？
6. 这个工作可能有什么深远的影响？

## 介绍
最好情况下，一个 DL 分布式框架应该：

1. 给定任意的并行方案后，能自动生成物理的执行计划，减少手工编程的代价
2. 更高级的需求是：框架能找到在任意NN网络结构和硬件组合下，最佳的并行策略

但，已有框架甚至都不满足条件一，即灵活支持多种并行策略。这是我们想在本论文里解决的问题：创新地重新设计DL框架

一些新兴的开源项目开发了专用的系统或者定制了库来更好地支撑模型和pipeline并行。例如，点击预估里的 HugeCTR，Megatron-LM和DeepSpeed 面向 大规模预训练 NLP 模型。InsightFace
是给大规模人脸识别的模型并行。但这些都是给特定应用定制的，并不能组合起来来形成一个通用的方案

也提出了一些插件来增强一些主流的DL框架来至此更复杂的并行策略。

Tensorflow： Mesh-TensorFlow, GShard 提供 API 来做并行。GPipe

PyTorch: PipeDream

由于现存框架设计之初没有预见到如此复杂的并行，导致在上面增量开发会带来显著的额外系统开销，需要研究员花费大量时间

## 2 背景和动机
一个 DNN 通常被表达为一个**逻辑**的op组成的计算图，通常是手工或者自动被编译器转化到由优化后的kernels组成的**物理图**来在运行时执行。分布式训练中包含数据（参数、梯度、激活值）
的通信。由于主机间带宽是设备内部的一到两个数量级的差异，所以 DL 框架应该把数据搬用当作跟计算一样的一等公民

### 2.1 把负载划分到空间领域(Spatial)

### 2.2 把负载划分到时间领域(Temporal)
