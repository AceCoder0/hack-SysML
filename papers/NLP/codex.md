1. 在解决的是什么问题？生成代码的问题
2. 为何成功，标志/准是什么？效果比较好
3. 在前人基础上的关键创新是什么？把 GPT 在代码数据集上进行微调
4. 关键结果有哪些？
5. 有哪些局限性？如何优化？
6. 这个工作可能有什么深远的影响？

## 摘要
基于 GPT 的语言模型，然后在公开的 GitHub 上的代码做微调（GPT 的卖点是不做微调）。

提出了一个 HumanEval 的评估集，codex 能解决 28.8% 的问题，而 GPT-3 能解决 0%，GPT-J 解决11.4%。有个简单有效的采样方法：同样的一个模型，跑一百遍，只要有一个能解决就行，那我们能解决 70.2% 的问题。

## 1 导言

GPT-3 能解决一些代码的问题，但是无法写更复杂的问题。因为训练数据里没怎么出现过代码。他们用代码数据集微调之后的权重叫做 Codex。为了 benchmark 我们的模型，创建了一个有 164 个原始编程问题的数据集，里面有单元测试来验证正确性。

为了进一步提升性能，在单独的、正确实现的函数集上进行微调（之前是github上的公开数据，质量层次不齐），就成了 Codex-S 模型。

## 2.1 正确性判断

 上面提到的164个问题，附带了单元测试用例，而且使用了 pass@k 这个指标：

1. n: total number of samples
2. c: number of correct samples
3. k: k in pass@k

## 2.3 执行生成代码的沙箱
避免被恶意代码攻击

## 3 Code Fine-Tuning

### 3.1 数据收集

54 M 个公开的的 github repo 里收集了 1MB 以下唯一的 Python 文件里 179 GB文件，过滤完之后有 159 GB。没提到文件的协议都是什么样的（导致了后面很多的批评）

### 3.2 方法
虽然用了 GPT3 权重没发现性能有什么提升，但有个好处是收敛更快：即训练时更快收敛。

采样的方法：
平常最简单的方法是每次都只保留概率最大的那个词，但这样有问题：
1. 不能保证全局最优：每次都选择当前概率最大的值，并不能保证最后生成的序列的概率是最大的值
2. 不管运行多少遍，每次都是一样的结果。

一般改进的方法是通过 beam search，可以维护 topk 个**当前为止效果最好**的。但作者使用了核采样的方法。 

Temperature 的意思：当 softmax 算指数的时候，线性层的温度除以一个温度 T。高温度会让候选之间的差距不大，而低温度会让候选之间的差异变大，而默认1是什么都不做。


## 4 supervised finetuning
做一个训练集，跟 humaneval 很相近。

1. 从各种程序比赛里拿到了1万个
2. 持续集成里带单元测试的各种函数（输入、输出、单测）

只留模型能解决的那些问题。

我们叫做带监督的微调。

### 4.4
额外准备了一个带标准答案的数据集（github上的是不一定有标准答案的

## 5 Docstring Generation
把 Docstring 挪到最后，这样 decoder 模型就又行了！

## 6 局限性
1. 样本局限性
2. Prompt 不同，生成的也不同
3. 理解长的问题能力比较弱

抄袭别人代码的问题

## 8 相关工作

绝大部分精力在数据的准备上面。原因是解决一个新问题
