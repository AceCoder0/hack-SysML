 LLM 在 SFT 阶段，可能遇到新的在 pretrain 阶段没有学到的事实性知识。经常推测这样教会模型事实性错误的幻觉性回复，因为模型被训练为产生不在 pretrain 知识里的事实。

结果表明在 SFT 阶段引入新的事实性知识，会有风险。而且支撑了 LLM: 大部分情况下从 pretrain 获取事实性知识，而 FT 只是教它怎么高效地使用的观点
