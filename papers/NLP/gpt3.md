作者基本换掉了

openai 的特点是 Clip 和 GPT3 一样，做了大量的实验，所以也有大量的作者

## 摘要
GPT3 特别大：175B的模型，在子任务上不做微调，在所有 NLP 的任务上取得了非常好的效果。GPT3 生成的新闻文章，让人类看不出是机器写的。

## 导言

任务相关的微调，存在三个问题：
1. 大数据集，需要标号
2. 样本没有出现在数据分布里的时候，泛化性并不一定比小模型好。如果在微调上效果好，并不能说明预训练模型的泛化性好
3. 人类不需要很大的标注数据

meta-learning（从大量的多样性的语料上学习到元信息），in context learning，想强调在 few shot 下，权重不做更新

## 方法

微调时学习率要调小一点，数据量也比较小。

One-shot：插入一个例子

Few-shot：看到几个例子

坏处：

1. 子任务的训练数据比较多，那不好直接放到输入里
2. 每一次都需要把上下文都放到里面

图里有8个模型，怎么设计的呢？当模型层数增加，宽度也应该随之增加，因为计算复杂度跟宽度成正比

批量大小增加到了非常大的 3.2M，这个非常大了，但小模型下bs会比较小，原因是小模型容易过拟合。

大模型下的过拟合不会那么严重，原因可能是两个：
1. 背后有一定的结构，不会像直接一个 MLP 那样过拟合
2. 模型越来越大，而且有结构，那搜的范围更广，容易搜到一个简单的模型结构

只写了模型的架构，用了半页

### 2.2 训练数据
1. 做一个二分类分类器，然后去过滤里面的数据，把高质量的 cc 数据集晒出来
2. 去重

在训练的时候，对不同的数据集，采样率不一样，虽然 CC 量很大，但因为质量不高而采样率比较低，这样保证每个批量里质量比较高。

### 2.3 模型评估

## 结果
当数据量固定，如果希望精度线性提高，那需要的算力是呈指数倍提高的。

## 5 局限性
1. 生成任务上效果一般，比如想让他写长文本，结果写了几段之后就开始重复了。
2. 语言模型，只能往前看
3. 均匀的预测下一个词，没有知道哪些词关键。没有画重点
4. 没有真实世界的反馈。人是需要真实
5. 样本有效性不够
6. 多样本，上下文学习。真的是从头学习？如果这样，那泛化性就很好了
7. 训练很贵
8. 无法解释

## 6 影响
