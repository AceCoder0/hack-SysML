1. 在解决的是什么问题？传统剪枝方法是在训练后剪枝，出来的稀疏结构的模型，只能用于推理。无法从头开始训练，只能继承大网络中权重来训练，得到相似性能
2. 为何成功，标志/准是什么？提出的算法，能在训练前找出中奖的彩票，然后用同样的初始化参数，进行训练。而且有一系列实验，支持了彩票理论里的假设
3. 在前人基础上的关键创新是什么？找出的pruning 的模型能够**从头**训练，达到一样的精度
4. 关键结果有哪些？
5. 有哪些局限性？如何优化？ learning rate warmup, initialization
6. 这个工作可能有什么深远的影响？彩票假设在相关但截然不同的**数据集**中普遍存在。能设计更好的网络结构

## 摘要

网络越稀疏，越不好训练。而根据彩票假设，越稠密，里面包含的中奖彩票越多，所以越好训练！

标准的剪枝技术，自然而然没有覆盖到能够初始化并高效训练的子网。彩票假设：dense, randomly-initialized, feed-forward networks 包含子网络（胜出的彩票）-- 单独训练时，在同样的迭代次数下，能达到和原版精度相同。我们找到的胜出的彩票，赢了初始化彩票：内部的连接的**初始化**权重，
能让训练变得高效。

发明了算法，能识别出胜出的彩票，设计了系列实验，支持假设，而且说明了初始化的重要性。发现 MNIST 和 CIFAR10 上，找到的彩票，大小上少 10-20%。而且训练的比原网络更快，而且准确度更高！

传统的 one-shot pruning: 训练一次，把 p% 的权重剪枝，剩下的权重重置

本文主要关注 iterative pruning: 在n个轮次里，反复训练、剪枝、重置。每次会剪枝上一轮留下的权重里的 p^(1/n)%。发现通过 iterative pruning，能找出胜出的彩票。

每次 pruning 之后，都得再用回上一次的参数初始化值。

initialize:

## 问题
1. dense是指？feed-forward networks，是不是就限制了场景了
2. 通过 iterative pruning 之后，如何识别出 wining tickets ？
