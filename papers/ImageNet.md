1. 在解决的是什么问题？在 ISVRC 比赛中获得更好的名次
2. 为何成功，标志/准是什么？ 比第二名高
3. 在前人基础上的关键创新是什么？ 有四点:
4. 关键结果有哪些？
5. 有哪些局限性？如何优化？ 只用了两块 GPU，而且为了减少通信，网络上有一些取舍
6. 这个工作可能有什么深远的影响？ 用他们提出的方法: ReLU, Data Augumentation, Dropout


## 四点关键创新：
1. 当时最大的 CNN
2. 实现了高度优化的 2D Conv的 GPU实现版本
3. 包含几个提高性能，减少训练时间的方法： ReLU, Pooling, 2 个 GPU 来跑
4. 由于网络加深了，很容易过拟合。防止的方法：数据增广，Dropout

## 为什么出现这种技术？
1. GPU 来了，可以在上面实现高效的矩阵算法
2. 有 ImageNet 这种大数据集。ImageNet 里图片大小不是固定的，而 ImageNet 里输入是 256*256。

## ImageNet 数据集
1500 万打了标签的数据集，有 2.2 万类目。

CNN 的网络容量像搞大，可以通过变化深度和宽度来做，

## 3. 网络架构

### 3.1 ReLU nonlinearity

之前用的都是 log 或者 tanh, 而这里是用了 max(0, x)。叫做 Rectified Linear Units(ReLUs)

使用 ReLU 代替 tanh 后，收敛速度更快

## 4. 减少过拟合

### 4.1 数据增广

相当于增加了更多数据

1. 改变图片里 RGB channel 里的 亮度
2. 产出图片水平翻转和镜像反转

### 4.2 droup out
用 0.5 的概率来将某个参数置为0.这种不会贡献到 forward，也不会计算 back propagation。这样每次输入数据一来，网络相当于是另外一种架构，但是他们共享权重。测试时，使用输出但是会乘以0.5.Dropout 会让收敛所需的时间加倍

