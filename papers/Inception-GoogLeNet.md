1. 在解决的是什么问题？让 ILSVRC 比赛中分类和目标检测效果更好
2. 为何成功，标志/准是什么？
3. 在前人基础上的关键创新是什么？考虑了多比例，设计了增加网络宽度但不增加参数量的方法
4. 关键结果有哪些？
5. 有哪些局限性？如何优化？
6. 这个工作可能有什么深远的影响？

在比赛中提交的一个 变体是 GoogLeNet，一个 22层的深度网络。

过去的三年里，由于 DL 里的发展，图片识别和目标检测发展迅速。让人兴奋的消息之一是，这些巨大进展不仅仅是更多硬件算力，更大数据集和更大模型，更多是由于新的思路，算法和变强的网络结构。比如并不需要新的数据，我们的 GoogLeNet 比两年前的 AlexNet 效果要好，而且参数量小了12倍。问题：怎么做到的呢？

CodeName 叫 Inception，而比赛中用的 GoogLeNet(大部分作者是Google的)

受 network-in-network 的启发，使用了他们发明的 1x1 卷积，两个目的：

1. 主要用于减少维度，这样可以去掉算力上的瓶颈，否则会限制网络的宽度和深度
2. 不仅能增加深度，还可以增加宽度，而不会给网络造成大的性能影响

## 3. 动力和高层考虑
简单增加网络尺寸有两个弊端：

1. 参数增加后，意味着网络更容易 过拟合。更大的数据集代价较高
2. 算力会迅速增加。而如果计算出来后发现这些增加的参数大部分都（近似）为0，那效果更加不好

解决方法是从全连接到稀疏连接的架构。

狗的图片里，有的狗占地大，有的小，所以需要的 kernel 大小不同。

## 4. 架构细节
Inception 结构的主要思路是在Conv NN 里找到一个基于最优的局部稀疏的结构，可以近似并覆盖稠密的组件。

![](imgs/inception-modules.png 
)

如上图左边，inception 里 。右图是使用了维度减少的方法。虽然在3x3 和 5x5里增加了额外的 1x1 卷积，但是减少了输入的 channels。

利用上面的 inception 模块，堆叠9次，就形成了 GoogLeNet：

![](imgs/GoogLeNet.png 
)

其中橘色是 stem，包含预备的 conv。紫色框是额外的分类器。目的是解决模型深度过深之后的梯度消失。最终的分类是结合了这话个额外分类后最后一层的结果

## 问题
1. filters 是指什么？

